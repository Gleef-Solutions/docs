---
title: 'Monitor an experiment'
description: "Follow how your experiments are performing in real-time"
---

To monitor the results of your experiments, simply go to your dashboard and select the experiment you'd like to view.

## Edit the name of the experiment
You have the option to edit the `Test name` at any time, and regardless of the status of your experiment (`Draft`, `In Progress`, `Paused`, `Finished`).
<img width="200" src="/images/monitor_details.png" alt="Name edition"/>
Simply edit it and then save the changes.

<Note>To prevent bias in your experiment, the only criteria you can update once it has been saved is the name. For additional information, please visit our [FAQ](/Q&A/QA)</Note>

## Start/Pause the experiment
### Drafted experiment
<img width="200" src="/images/monitor_draft.png" alt="Draft experiment"/>

When you create an experiment, you have the option to save it as a draft instead of running it directly. A `Draft` experiment signifies it has never run and therefore, doesn't have any data to display. You can start the experiment whenever you're ready.

<Warning>If an experiment has been in the "draft" stage for a while, it's important to verify that the page hasn't undergone any changes in the meantime, so that the targeted wording for the experiment is still relevant.</Warning>

### Paused experiment
<img width="200" src="/images/monitor_paused.png" alt="Not running experiment"/>

When an experiment is `Paused`, it means that it was previously launched but then stopped. At this point, visitors will only see the baseline. The experiment may have some saved data from when it was live. To restart a paused experiment, click the restart button. The experiment will then display variations to visitors and the new data collected will be added to the previous data.
<Note>If you pause an experiment, you might still see the different variations on your website for up to 7 days. Do not worry, new visitors will not be subject to the experiment. Learn more about it [in our FAQ.](/Q&A/trouble-shooting#i-have-paused-an-experiment-but-still-see-live-variations-on-my-website-why)</Note>

### Running experiment
<img width="200" src="/images/monitor_running.png" alt="In progress experiment"/>

When an experiment is in progress, you can pause it at any time. It will no longer be live on your webpage. However, you can switch it back on later to collect additional data.

Reasons why you might want to pause an experiment:

- The wording under experiment has been removed from the page
- You're aware of a particular event that could potentially introduce bias into your experiment

<Warning>It's advisable to avoid pausing an experiment for an extended period, as it may introduce bias and affect the results.</Warning>

If you pause an experiment that has already reached statistical significance, it will be marked as `finished`.


## Finish the experiment
When the experiment reaches statistical significance, you can pause it. This will change the experiment‚Äôs status to `finished`. It's time to start analyzing the results!


## Analyze results
### Significance
<img width="200" src="/images/monitor_not-significant.png" alt="Not significant experiment"/>

Statistical significance is based on various parameters. Gleef uses an automatic calculation to determine whether your results are significant.
For detailed insight on how this is done, refer to our [statistics Q&A](/Q&A/statistics-data).

Continue running the experiment until you achieve statistical significance. Ending the experiment prematurely could hinder the reliability of your results. Remember, significance is closely related to the magnitude of the conversion difference between variations.
For example, if you have a 10% conversion difference between two variations, your experiment may reach significance much faster than if the difference were only 1%.

<Note>Significance is fixed at 95% for all experiments, and currently, it is not customizable.</Note>

For the moment, Gleef does not offer the possibility of managing the significance parameters of experiments. This is automatically triggered when the 95% confidence level is reached (p-value of 0.05). You can see the critical Z value directly in the console when you open the dashboard on a specific experiment. As a reminder, the values are as follows:

| Confidence Level | Critical Value, ùëçùëê |
| -------- | -------------------------- |
| 99%      | 2.575                      |
| 95%      | 2.33                       |
| 90%      | 1.645                      |
| 80%      | 1.28                       |

The console displays the critical Z value and the p-value.

<Tip>Please note that the significance of experiments is calculated purely from a mathematical point of view for the time being, and no other rule is involved in changing the dot determining the significance of the experiment.
However, we recommend that you achieve the following values to ensure the validity of the experiment.</Tip>

Value to look at on top of statistical significance, before taking any decision on your wording:
- At least 5,000 unique visitors per variation;
- To run the test for at least 14 days (two business cycles);
- Achieve 250 conversions.

### Conversion & growth
<img width="200" src="/images/monitor_results.png" alt="Results"/>
At any time, you can access and monitor the results of your experiment, observing the conversion rates of each variation, and the improvement compared to the `baseline`, which represents the original wording being tested.

<Tip>
    Hover over the conversion or growth metrics for detailed figures.
    <img width="200" src="/images/monitor_hover.png" alt="Hover conversion"/>
</Tip>